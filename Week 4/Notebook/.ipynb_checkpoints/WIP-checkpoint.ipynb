{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "import requests\n",
    "import bs4\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#LINK = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=\"\n",
    "\n",
    "#page_start_from = '&start='       \n",
    "#df = pd.DataFrame()      \n",
    " \n",
    "#for city in ('New+York%2C+NY', 'Chicago%2C+IL', 'San+Francisco%2C+CA', 'Austin%2C+TX',\n",
    "#            \"Atlanta%2C+GA\", \"Los+Angeles%2C+CA\", \"Washington%2C+DC\" ):\n",
    "#    for page in range(1,21): \n",
    "#        page = (page-1) * 10  \n",
    "#        url = \"%s%s%s%d\" % (LINK, city, page_start_from, page) \n",
    "#        r = requests.get(url)\n",
    "#        soup = BeautifulSoup(r.content) \n",
    "#        results = soup.find_all(\"div\", {'class' : ' row result'}) \n",
    "    \n",
    "#        for i in range(len(results)):\n",
    "#            title    = results[i].find (\"a\", {\"class\": \"turnstileLink\"}).get_text().strip()\n",
    "#            company  = results[i].find (\"span\", {\"class\": \"company\"}).get_text().strip()\n",
    "#            location = results[i].find (\"span\", {\"class\": \"location\"}).get_text().strip()\n",
    "#            summary  = results[i].find (\"span\", {\"class\": \"summary\"}).get_text().strip()        \n",
    "        \n",
    "#            df = df.append({\"Company Name\": company, \"Job Title\": title, \"Location\": location,\n",
    "#                            \"Job Summary\": summary}, ignore_index=True)\n",
    "\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1218,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#def justCity(var):\n",
    "#    varsplitted = var.split(\",\")\n",
    "#    newList = varsplitted[0]\n",
    "#    return newList\n",
    "#finalVar = [justCity(x) for x in df[\"Location\"].tolist()]\n",
    "#df[\"Location\"] = finalVar\n",
    "\n",
    "#df[\"Salary\"] = \"L\"\n",
    "#df.head()\n",
    "\n",
    "#df = df[(df.Location == 'New York') | (df.Location == 'Chicago') | (df.Location == 'San Francisco') | \n",
    "#        (df.Location == 'Austin') | (df.Location == \"Atlanta\") | (df.Location == \"Los Angeles\") | \n",
    "#        (df.Location == \"Washington\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.drop_duplicates([\"Company Name\", \"Job Summary\", \"Job Title\", \"Location\"], keep='last', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1222,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#URL = \"http://www.indeed.com/jobs?q=data+scientist+%24120%2C000&l=\"\n",
    "\n",
    "#page_start_from = '&start='      \n",
    "#df2 = pd.DataFrame()   \n",
    " \n",
    "#for city in ('New+York%2C+NY', 'Chicago%2C+IL', 'San+Francisco%2C+CA', 'Austin%2C+TX',\n",
    "#            \"Atlanta%2C+GA\", \"Los+Angeles%2C+CA\", \"Washington%2C+DC\" ):\n",
    "#    for page in range(1,21): \n",
    "#        page = (page-1) * 10  \n",
    "#        url = \"%s%s%s%d\" % (URL, city, page_start_from, page) \n",
    "#        r = requests.get(url)\n",
    "#        soup = BeautifulSoup(r.content) \n",
    "#        results = soup.find_all(\"div\", {'class' : ' row result'}) \n",
    "    \n",
    "#        for i in range(len(results)):\n",
    "#            title    = results[i].find (\"a\", {\"class\": \"turnstileLink\"}).get_text().strip()\n",
    "#            company  = results[i].find (\"span\", {\"class\": \"company\"}).get_text().strip()\n",
    "#            location = results[i].find (\"span\", {\"class\": \"location\"}).get_text().strip()\n",
    "#            summary  = results[i].find (\"span\", {\"class\": \"summary\"}).get_text().strip()        \n",
    "        \n",
    "#            df2 = df2.append({\"Company Name\": company, \"Job Title\": title, \"Location\": location,\n",
    "#                            \"Job Summary\": summary}, ignore_index=True)\n",
    "\n",
    "#df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#def justCity(var):\n",
    "#    varsplitted = var.split(\",\")\n",
    "#    newList = varsplitted[0]\n",
    "#    return newList\n",
    "#finalVar = [justCity(x) for x in df2[\"Location\"].tolist()]\n",
    "#df2[\"Location\"] = finalVar\n",
    "\n",
    "#df2[\"Salary\"] = \"H\"\n",
    "#df2 = df2[(df2.Location == 'New York') | (df2.Location == 'Chicago') | (df2.Location == 'San Francisco') | \n",
    "#          (df2.Location == 'Austin') | (df2.Location == \"Atlanta\") | (df2.Location == \"Los Angeles\") | \n",
    "#          (df2.Location == \"Washington\")]\n",
    "#df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df2.drop_duplicates([\"Company Name\", \"Job Summary\", \"Job Title\", \"Location\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1227,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#mergedDF = [df, df2]\n",
    "#newDF = pd.concat(mergedDF)\n",
    "#newDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#newDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#newDF.drop_duplicates([\"Company Name\", \"Job Summary\", \"Job Title\", \"Location\"], keep='last', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#newDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#newDF.index = range(len(newDF))\n",
    "#newDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print newDF[ (newDF[\"Salary\"] == \"H\")].shape\n",
    "#print newDF[ (newDF[\"Salary\"] == \"L\")].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1233,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#newDF.to_csv(\"../Assets/indeedSalaryJobs.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../Assets/indeedSalaryJobs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Job Summary</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S&amp;P Global Ratings</td>\n",
       "      <td>Research and resolve data maintenance requests related to Corporate &amp; Government and Structured Finance ratings data....</td>\n",
       "      <td>Statistician</td>\n",
       "      <td>New York</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>Bloomberg's Global Data division houses an incredible team of data oriented professionals who work to solve tangible business challenges....</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>New York</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AllianceBernstein</td>\n",
       "      <td>Job Number: 7473 Position Title: VP/Research Analyst Location_formattedLocationLong: New York, New York US External Description: Research is the</td>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>New York</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>Evaluate cutting-edge big data technologies/software (e.g. Strong Computer Science fundamentals (algorithms, data structures)....</td>\n",
       "      <td>Senior Data Engineer for Search and Discoverability Team</td>\n",
       "      <td>New York</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eTemp</td>\n",
       "      <td>High growth company focused on using data science to transform the way individuals are hired, is looking for an inventive, collaborative, methodologically...</td>\n",
       "      <td>Mid - Senior Level Data Scientist</td>\n",
       "      <td>New York</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Company Name  \\\n",
       "0  S&P Global Ratings   \n",
       "1           Bloomberg   \n",
       "2   AllianceBernstein   \n",
       "3           Bloomberg   \n",
       "4               eTemp   \n",
       "\n",
       "                                                                                                                                                     Job Summary  \\\n",
       "0                                       Research and resolve data maintenance requests related to Corporate & Government and Structured Finance ratings data....   \n",
       "1                   Bloomberg's Global Data division houses an incredible team of data oriented professionals who work to solve tangible business challenges....   \n",
       "2               Job Number: 7473 Position Title: VP/Research Analyst Location_formattedLocationLong: New York, New York US External Description: Research is the   \n",
       "3                              Evaluate cutting-edge big data technologies/software (e.g. Strong Computer Science fundamentals (algorithms, data structures)....   \n",
       "4  High growth company focused on using data science to transform the way individuals are hired, is looking for an inventive, collaborative, methodologically...   \n",
       "\n",
       "                                                  Job Title  Location Salary  \n",
       "0                                              Statistician  New York      L  \n",
       "1                                 Machine Learning Engineer  New York      L  \n",
       "2                                          Research Analyst  New York      L  \n",
       "3  Senior Data Engineer for Search and Discoverability Team  New York      L  \n",
       "4                         Mid - Senior Level Data Scientist  New York      L  "
      ]
     },
     "execution_count": 1235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[\"Salary\"] = data[\"Salary\"].map({\"H\": 1, \"L\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Location</th>\n",
       "      <th>Atlanta</th>\n",
       "      <th>Austin</th>\n",
       "      <th>Chicago</th>\n",
       "      <th>Los Angeles</th>\n",
       "      <th>New York</th>\n",
       "      <th>San Francisco</th>\n",
       "      <th>Washington</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Salary</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119</td>\n",
       "      <td>138</td>\n",
       "      <td>128</td>\n",
       "      <td>68</td>\n",
       "      <td>117</td>\n",
       "      <td>88</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>31</td>\n",
       "      <td>78</td>\n",
       "      <td>26</td>\n",
       "      <td>172</td>\n",
       "      <td>131</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Location  Atlanta  Austin  Chicago  Los Angeles  New York  San Francisco  \\\n",
       "Salary                                                                     \n",
       "0             119     138      128           68       117             88   \n",
       "1              34      31       78           26       172            131   \n",
       "\n",
       "Location  Washington  \n",
       "Salary                \n",
       "0                 77  \n",
       "1                 37  "
      ]
     },
     "execution_count": 1237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(data[\"Salary\"], data[\"Location\"], rownames = [\"Salary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1238,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Salary</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Job Summary</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Atlanta</th>\n",
       "      <th>Austin</th>\n",
       "      <th>Chicago</th>\n",
       "      <th>Los Angeles</th>\n",
       "      <th>New York</th>\n",
       "      <th>San Francisco</th>\n",
       "      <th>Washington</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>S&amp;P Global Ratings</td>\n",
       "      <td>Research and resolve data maintenance requests related to Corporate &amp; Government and Structured Finance ratings data....</td>\n",
       "      <td>Statistician</td>\n",
       "      <td>New York</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>Bloomberg's Global Data division houses an incredible team of data oriented professionals who work to solve tangible business challenges....</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>New York</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>AllianceBernstein</td>\n",
       "      <td>Job Number: 7473 Position Title: VP/Research Analyst Location_formattedLocationLong: New York, New York US External Description: Research is the</td>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>New York</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>Evaluate cutting-edge big data technologies/software (e.g. Strong Computer Science fundamentals (algorithms, data structures)....</td>\n",
       "      <td>Senior Data Engineer for Search and Discoverability Team</td>\n",
       "      <td>New York</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>eTemp</td>\n",
       "      <td>High growth company focused on using data science to transform the way individuals are hired, is looking for an inventive, collaborative, methodologically...</td>\n",
       "      <td>Mid - Senior Level Data Scientist</td>\n",
       "      <td>New York</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Salary        Company Name  \\\n",
       "0       0  S&P Global Ratings   \n",
       "1       0           Bloomberg   \n",
       "2       0   AllianceBernstein   \n",
       "3       0           Bloomberg   \n",
       "4       0               eTemp   \n",
       "\n",
       "                                                                                                                                                     Job Summary  \\\n",
       "0                                       Research and resolve data maintenance requests related to Corporate & Government and Structured Finance ratings data....   \n",
       "1                   Bloomberg's Global Data division houses an incredible team of data oriented professionals who work to solve tangible business challenges....   \n",
       "2               Job Number: 7473 Position Title: VP/Research Analyst Location_formattedLocationLong: New York, New York US External Description: Research is the   \n",
       "3                              Evaluate cutting-edge big data technologies/software (e.g. Strong Computer Science fundamentals (algorithms, data structures)....   \n",
       "4  High growth company focused on using data science to transform the way individuals are hired, is looking for an inventive, collaborative, methodologically...   \n",
       "\n",
       "                                                  Job Title  Location  \\\n",
       "0                                              Statistician  New York   \n",
       "1                                 Machine Learning Engineer  New York   \n",
       "2                                          Research Analyst  New York   \n",
       "3  Senior Data Engineer for Search and Discoverability Team  New York   \n",
       "4                         Mid - Senior Level Data Scientist  New York   \n",
       "\n",
       "   Atlanta  Austin  Chicago  Los Angeles  New York  San Francisco  Washington  \n",
       "0      0.0     0.0      0.0          0.0       1.0            0.0         0.0  \n",
       "1      0.0     0.0      0.0          0.0       1.0            0.0         0.0  \n",
       "2      0.0     0.0      0.0          0.0       1.0            0.0         0.0  \n",
       "3      0.0     0.0      0.0          0.0       1.0            0.0         0.0  \n",
       "4      0.0     0.0      0.0          0.0       1.0            0.0         0.0  "
      ]
     },
     "execution_count": 1238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummyData = pd.get_dummies(data[\"Location\"])\n",
    "newData = data[[\"Salary\", \"Company Name\", \"Job Summary\", \"Job Title\", \"Location\"]].join(dummyData)\n",
    "newData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1244, 13)"
      ]
     },
     "execution_count": 1256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Atlanta  Austin  Chicago  Intercept  Los Angeles  San Francisco  \\\n",
      "0         0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "1         0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "2         0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "3         0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "4         0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "5         0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "6         0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "7         0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "8         0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "9         0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "10        0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "11        0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "12        0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "13        0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "14        0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "15        0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "16        0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "17        0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "18        0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "19        0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "20        0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "21        0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "22        0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "23        0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "24        0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "25        0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "26        0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "27        0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "28        0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "29        0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "...       ...     ...      ...        ...          ...            ...   \n",
      "1214      0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "1215      0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "1216      0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "1217      0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "1218      0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "1219      0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "1220      0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "1221      0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "1222      0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "1223      0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "1224      0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "1225      0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "1226      0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "1227      0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "1228      0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "1229      0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "1230      0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "1231      0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "1232      0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "1233      0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "1234      0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "1235      0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "1236      0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "1237      0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "1238      0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "1239      0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "1240      0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "1241      0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "1242      0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "1243      0.0     0.0      0.0        1.0          0.0            0.0   \n",
      "\n",
      "      Washington  \n",
      "0            0.0  \n",
      "1            0.0  \n",
      "2            0.0  \n",
      "3            0.0  \n",
      "4            0.0  \n",
      "5            0.0  \n",
      "6            0.0  \n",
      "7            0.0  \n",
      "8            0.0  \n",
      "9            0.0  \n",
      "10           0.0  \n",
      "11           0.0  \n",
      "12           0.0  \n",
      "13           0.0  \n",
      "14           0.0  \n",
      "15           0.0  \n",
      "16           0.0  \n",
      "17           0.0  \n",
      "18           0.0  \n",
      "19           0.0  \n",
      "20           0.0  \n",
      "21           0.0  \n",
      "22           0.0  \n",
      "23           0.0  \n",
      "24           0.0  \n",
      "25           0.0  \n",
      "26           0.0  \n",
      "27           0.0  \n",
      "28           0.0  \n",
      "29           0.0  \n",
      "...          ...  \n",
      "1214         1.0  \n",
      "1215         1.0  \n",
      "1216         1.0  \n",
      "1217         1.0  \n",
      "1218         1.0  \n",
      "1219         1.0  \n",
      "1220         1.0  \n",
      "1221         1.0  \n",
      "1222         1.0  \n",
      "1223         1.0  \n",
      "1224         1.0  \n",
      "1225         1.0  \n",
      "1226         1.0  \n",
      "1227         1.0  \n",
      "1228         1.0  \n",
      "1229         1.0  \n",
      "1230         1.0  \n",
      "1231         1.0  \n",
      "1232         1.0  \n",
      "1233         1.0  \n",
      "1234         1.0  \n",
      "1235         1.0  \n",
      "1236         1.0  \n",
      "1237         1.0  \n",
      "1238         1.0  \n",
      "1239         1.0  \n",
      "1240         1.0  \n",
      "1241         1.0  \n",
      "1242         1.0  \n",
      "1243         1.0  \n",
      "\n",
      "[1244 rows x 7 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Lola/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:2: FutureWarning: using '+' to provide set union with Indexes is deprecated, use '|' or .union()\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "newData[\"Intercept\"] = 1.0\n",
    "X = newData[ newData.columns[5:9] + newData.columns[10:] ]\n",
    "y = newData.Salary\n",
    "\n",
    "\n",
    "#data_target   = newData[\"Salary\"]\n",
    "#data_features = newData[[\"Atlanta\", \"Austin\", \"Chicago\", \"Los Angeles\", \n",
    "                         #\"New York\", \"Washington\", \"Intercept\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.617467\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>Salary</td>      <th>  No. Observations:  </th>  <td>  1244</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  1237</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     6</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Thu, 30 Jun 2016</td> <th>  Pseudo R-squ.:     </th>  <td>0.08733</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>17:57:22</td>     <th>  Log-Likelihood:    </th> <td> -768.13</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -841.63</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>3.324e-29</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atlanta</th>       <td>   -1.6381</td> <td>    0.228</td> <td>   -7.171</td> <td> 0.000</td> <td>   -2.086    -1.190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Austin</th>        <td>   -1.8786</td> <td>    0.232</td> <td>   -8.094</td> <td> 0.000</td> <td>   -2.333    -1.424</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Chicago</th>       <td>   -0.8806</td> <td>    0.187</td> <td>   -4.708</td> <td> 0.000</td> <td>   -1.247    -0.514</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>     <td>    0.3853</td> <td>    0.120</td> <td>    3.215</td> <td> 0.001</td> <td>    0.150     0.620</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Los Angeles</th>   <td>   -1.3467</td> <td>    0.260</td> <td>   -5.182</td> <td> 0.000</td> <td>   -1.856    -0.837</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>San Francisco</th> <td>    0.0125</td> <td>    0.183</td> <td>    0.069</td> <td> 0.945</td> <td>   -0.345     0.371</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Washington</th>    <td>   -1.1182</td> <td>    0.233</td> <td>   -4.795</td> <td> 0.000</td> <td>   -1.575    -0.661</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                 Salary   No. Observations:                 1244\n",
       "Model:                          Logit   Df Residuals:                     1237\n",
       "Method:                           MLE   Df Model:                            6\n",
       "Date:                Thu, 30 Jun 2016   Pseudo R-squ.:                 0.08733\n",
       "Time:                        17:57:22   Log-Likelihood:                -768.13\n",
       "converged:                       True   LL-Null:                       -841.63\n",
       "                                        LLR p-value:                 3.324e-29\n",
       "=================================================================================\n",
       "                    coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "---------------------------------------------------------------------------------\n",
       "Atlanta          -1.6381      0.228     -7.171      0.000        -2.086    -1.190\n",
       "Austin           -1.8786      0.232     -8.094      0.000        -2.333    -1.424\n",
       "Chicago          -0.8806      0.187     -4.708      0.000        -1.247    -0.514\n",
       "Intercept         0.3853      0.120      3.215      0.001         0.150     0.620\n",
       "Los Angeles      -1.3467      0.260     -5.182      0.000        -1.856    -0.837\n",
       "San Francisco     0.0125      0.183      0.069      0.945        -0.345     0.371\n",
       "Washington       -1.1182      0.233     -4.795      0.000        -1.575    -0.661\n",
       "=================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 1262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = sm.Logit(y, X)\n",
    "result = logit.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2.5%</th>\n",
       "      <th>97.5%</th>\n",
       "      <th>Coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Atlanta</th>\n",
       "      <td>0.124210</td>\n",
       "      <td>0.304104</td>\n",
       "      <td>0.194352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austin</th>\n",
       "      <td>0.096958</td>\n",
       "      <td>0.240821</td>\n",
       "      <td>0.152806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chicago</th>\n",
       "      <td>0.287283</td>\n",
       "      <td>0.598100</td>\n",
       "      <td>0.414517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>1.162350</td>\n",
       "      <td>1.859295</td>\n",
       "      <td>1.470085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Los Angeles</th>\n",
       "      <td>0.156288</td>\n",
       "      <td>0.432830</td>\n",
       "      <td>0.260089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>San Francisco</th>\n",
       "      <td>0.707914</td>\n",
       "      <td>1.448476</td>\n",
       "      <td>1.012619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Washington</th>\n",
       "      <td>0.206958</td>\n",
       "      <td>0.516244</td>\n",
       "      <td>0.326865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   2.5%     97.5%      Coef\n",
       "Atlanta        0.124210  0.304104  0.194352\n",
       "Austin         0.096958  0.240821  0.152806\n",
       "Chicago        0.287283  0.598100  0.414517\n",
       "Intercept      1.162350  1.859295  1.470085\n",
       "Los Angeles    0.156288  0.432830  0.260089\n",
       "San Francisco  0.707914  1.448476  1.012619\n",
       "Washington     0.206958  0.516244  0.326865"
      ]
     },
     "execution_count": 1263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confInt = result.conf_int()\n",
    "confInt[\"Coef\"] = result.params\n",
    "confInt.columns = [\"2.5%\", \"97.5%\", \"Coef\"]\n",
    "np.exp(confInt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Lola/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/Users/Lola/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Atlanta</th>\n",
       "      <th>Austin</th>\n",
       "      <th>Chicago</th>\n",
       "      <th>Intercept</th>\n",
       "      <th>Los Angeles</th>\n",
       "      <th>San Francisco</th>\n",
       "      <th>Washington</th>\n",
       "      <th>actualSalary</th>\n",
       "      <th>predictedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.595156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.595156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.595156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.595156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.595156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Atlanta  Austin  Chicago  Intercept  Los Angeles  San Francisco  \\\n",
       "0      0.0     0.0      0.0        1.0          0.0            0.0   \n",
       "1      0.0     0.0      0.0        1.0          0.0            0.0   \n",
       "2      0.0     0.0      0.0        1.0          0.0            0.0   \n",
       "3      0.0     0.0      0.0        1.0          0.0            0.0   \n",
       "4      0.0     0.0      0.0        1.0          0.0            0.0   \n",
       "\n",
       "   Washington  actualSalary  predictedSalary  \n",
       "0         0.0             0         0.595156  \n",
       "1         0.0             0         0.595156  \n",
       "2         0.0             0         0.595156  \n",
       "3         0.0             0         0.595156  \n",
       "4         0.0             0         0.595156  "
      ]
     },
     "execution_count": 1267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[\"actualSalary\"] = y\n",
    "dFrame = X\n",
    "dFrame.head()\n",
    "dFrame['predictedSalary'] = result.predict( dFrame[ dFrame.columns[0:7] ] )\n",
    "dFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Lola/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Atlanta</th>\n",
       "      <th>Austin</th>\n",
       "      <th>Chicago</th>\n",
       "      <th>Intercept</th>\n",
       "      <th>Los Angeles</th>\n",
       "      <th>San Francisco</th>\n",
       "      <th>Washington</th>\n",
       "      <th>actualSalary</th>\n",
       "      <th>predictedSalary</th>\n",
       "      <th>approxPredict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.595156</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.595156</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.595156</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.595156</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.595156</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Atlanta  Austin  Chicago  Intercept  Los Angeles  San Francisco  \\\n",
       "0      0.0     0.0      0.0        1.0          0.0            0.0   \n",
       "1      0.0     0.0      0.0        1.0          0.0            0.0   \n",
       "2      0.0     0.0      0.0        1.0          0.0            0.0   \n",
       "3      0.0     0.0      0.0        1.0          0.0            0.0   \n",
       "4      0.0     0.0      0.0        1.0          0.0            0.0   \n",
       "\n",
       "   Washington  actualSalary  predictedSalary  approxPredict  \n",
       "0         0.0             0         0.595156              1  \n",
       "1         0.0             0         0.595156              1  \n",
       "2         0.0             0         0.595156              1  \n",
       "3         0.0             0         0.595156              1  \n",
       "4         0.0             0         0.595156              1  "
      ]
     },
     "execution_count": 1269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc = dFrame[\"predictedSalary\"]\n",
    "cutoff = 0.5\n",
    "dFrame[\"approxPredict\"] = [0 if i < cutoff else 1 for i in abc]\n",
    "dFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "approxPredict    0    1\n",
      "actual                 \n",
      "0              530  205\n",
      "1              206  303\n"
     ]
    }
   ],
   "source": [
    "print pd.crosstab(\n",
    "                    dFrame[\"actualSalary\"],\n",
    "                    dFrame[\"approxPredict\"], \n",
    "                    rownames=[\"actual\"]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Lola/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:2: FutureWarning: using '+' to provide set union with Indexes is deprecated, use '|' or .union()\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "newData[\"Intercept\"] = 1.0\n",
    "X = newData[ newData.columns[5:9] + newData.columns[10:] ]\n",
    "y = newData.Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1246,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.607238\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>Salary</td>      <th>  No. Observations:  </th>  <td>   870</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   863</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     6</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Thu, 30 Jun 2016</td> <th>  Pseudo R-squ.:     </th>  <td>0.09516</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>17:55:32</td>     <th>  Log-Likelihood:    </th> <td> -528.30</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -583.86</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>1.185e-21</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atlanta</th>       <td>   -1.9557</td> <td>    0.296</td> <td>   -6.615</td> <td> 0.000</td> <td>   -2.535    -1.376</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Austin</th>        <td>   -1.7212</td> <td>    0.274</td> <td>   -6.276</td> <td> 0.000</td> <td>   -2.259    -1.184</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Chicago</th>       <td>   -0.8734</td> <td>    0.227</td> <td>   -3.856</td> <td> 0.000</td> <td>   -1.317    -0.429</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>     <td>    0.3028</td> <td>    0.146</td> <td>    2.080</td> <td> 0.038</td> <td>    0.017     0.588</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Los Angeles</th>   <td>   -1.1295</td> <td>    0.299</td> <td>   -3.772</td> <td> 0.000</td> <td>   -1.716    -0.543</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>San Francisco</th> <td>    0.1402</td> <td>    0.219</td> <td>    0.639</td> <td> 0.523</td> <td>   -0.290     0.570</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Washington</th>    <td>   -1.1137</td> <td>    0.285</td> <td>   -3.904</td> <td> 0.000</td> <td>   -1.673    -0.555</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                 Salary   No. Observations:                  870\n",
       "Model:                          Logit   Df Residuals:                      863\n",
       "Method:                           MLE   Df Model:                            6\n",
       "Date:                Thu, 30 Jun 2016   Pseudo R-squ.:                 0.09516\n",
       "Time:                        17:55:32   Log-Likelihood:                -528.30\n",
       "converged:                       True   LL-Null:                       -583.86\n",
       "                                        LLR p-value:                 1.185e-21\n",
       "=================================================================================\n",
       "                    coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "---------------------------------------------------------------------------------\n",
       "Atlanta          -1.9557      0.296     -6.615      0.000        -2.535    -1.376\n",
       "Austin           -1.7212      0.274     -6.276      0.000        -2.259    -1.184\n",
       "Chicago          -0.8734      0.227     -3.856      0.000        -1.317    -0.429\n",
       "Intercept         0.3028      0.146      2.080      0.038         0.017     0.588\n",
       "Los Angeles      -1.1295      0.299     -3.772      0.000        -1.716    -0.543\n",
       "San Francisco     0.1402      0.219      0.639      0.523        -0.290     0.570\n",
       "Washington       -1.1137      0.285     -3.904      0.000        -1.673    -0.555\n",
       "=================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 1246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.70, random_state=15)\n",
    "\n",
    "logit = sm.Logit(y_train, X_train)\n",
    "result = logit.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2.5%</th>\n",
       "      <th>97.5%</th>\n",
       "      <th>Coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Atlanta</th>\n",
       "      <td>0.079249</td>\n",
       "      <td>0.252509</td>\n",
       "      <td>0.141461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austin</th>\n",
       "      <td>0.104486</td>\n",
       "      <td>0.306147</td>\n",
       "      <td>0.178853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chicago</th>\n",
       "      <td>0.267858</td>\n",
       "      <td>0.650890</td>\n",
       "      <td>0.417548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>1.017560</td>\n",
       "      <td>1.800769</td>\n",
       "      <td>1.353659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Los Angeles</th>\n",
       "      <td>0.179720</td>\n",
       "      <td>0.581221</td>\n",
       "      <td>0.323198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>San Francisco</th>\n",
       "      <td>0.748437</td>\n",
       "      <td>1.768537</td>\n",
       "      <td>1.150495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Washington</th>\n",
       "      <td>0.187703</td>\n",
       "      <td>0.574310</td>\n",
       "      <td>0.328328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   2.5%     97.5%      Coef\n",
       "Atlanta        0.079249  0.252509  0.141461\n",
       "Austin         0.104486  0.306147  0.178853\n",
       "Chicago        0.267858  0.650890  0.417548\n",
       "Intercept      1.017560  1.800769  1.353659\n",
       "Los Angeles    0.179720  0.581221  0.323198\n",
       "San Francisco  0.748437  1.768537  1.150495\n",
       "Washington     0.187703  0.574310  0.328328"
      ]
     },
     "execution_count": 1247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confInt = result.conf_int()\n",
    "confInt[\"Coef\"] = result.params\n",
    "confInt.columns = [\"2.5%\", \"97.5%\", \"Coef\"]\n",
    "np.exp(confInt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1248,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Lola/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/Users/Lola/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Atlanta</th>\n",
       "      <th>Austin</th>\n",
       "      <th>Chicago</th>\n",
       "      <th>Intercept</th>\n",
       "      <th>Los Angeles</th>\n",
       "      <th>San Francisco</th>\n",
       "      <th>Washington</th>\n",
       "      <th>actualSalary</th>\n",
       "      <th>predictedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.361111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.575130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.194915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.575130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.304348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Atlanta  Austin  Chicago  Intercept  Los Angeles  San Francisco  \\\n",
       "917       0.0     0.0      1.0        1.0          0.0            0.0   \n",
       "77        0.0     0.0      0.0        1.0          0.0            0.0   \n",
       "408       0.0     1.0      0.0        1.0          0.0            0.0   \n",
       "94        0.0     0.0      0.0        1.0          0.0            0.0   \n",
       "1187      0.0     0.0      0.0        1.0          1.0            0.0   \n",
       "\n",
       "      Washington  actualSalary  predictedSalary  \n",
       "917          0.0             1         0.361111  \n",
       "77           0.0             0         0.575130  \n",
       "408          0.0             0         0.194915  \n",
       "94           0.0             0         0.575130  \n",
       "1187         0.0             1         0.304348  "
      ]
     },
     "execution_count": 1248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[\"actualSalary\"] = y_test\n",
    "dfTrain = X_test\n",
    "#dfTrain.head()\n",
    "dfTrain['predictedSalary'] = result.predict( dfTrain[ dfTrain.columns[0:7] ] )\n",
    "dfTrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Lola/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Atlanta</th>\n",
       "      <th>Austin</th>\n",
       "      <th>Chicago</th>\n",
       "      <th>Intercept</th>\n",
       "      <th>Los Angeles</th>\n",
       "      <th>San Francisco</th>\n",
       "      <th>Washington</th>\n",
       "      <th>actualSalary</th>\n",
       "      <th>predictedSalary</th>\n",
       "      <th>approxPredict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.575130</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.194915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.575130</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Atlanta  Austin  Chicago  Intercept  Los Angeles  San Francisco  \\\n",
       "917       0.0     0.0      1.0        1.0          0.0            0.0   \n",
       "77        0.0     0.0      0.0        1.0          0.0            0.0   \n",
       "408       0.0     1.0      0.0        1.0          0.0            0.0   \n",
       "94        0.0     0.0      0.0        1.0          0.0            0.0   \n",
       "1187      0.0     0.0      0.0        1.0          1.0            0.0   \n",
       "\n",
       "      Washington  actualSalary  predictedSalary  approxPredict  \n",
       "917          0.0             1         0.361111              0  \n",
       "77           0.0             0         0.575130              1  \n",
       "408          0.0             0         0.194915              0  \n",
       "94           0.0             0         0.575130              1  \n",
       "1187         0.0             1         0.304348              0  "
      ]
     },
     "execution_count": 1249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xyz = dfTrain[\"predictedSalary\"]\n",
    "cutoff = 0.5\n",
    "dfTrain[\"approxPredict\"] = [0 if i < cutoff else 1 for i in xyz]\n",
    "dfTrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "approxPredict    0   1\n",
      "actual                \n",
      "0              147  62\n",
      "1               68  97\n"
     ]
    }
   ],
   "source": [
    "print pd.crosstab(\n",
    "                    dfTrain[\"actualSalary\"],\n",
    "                    dfTrain[\"approxPredict\"], \n",
    "                    rownames=[\"actual\"]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[147,  62],\n",
       "       [ 68,  97]])"
      ]
     },
     "execution_count": 1251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(dfTrain[\"actualSalary\"], dfTrain[\"approxPredict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.66961414791\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "#import matplotlib.pyplot as plt\n",
    "lm = linear_model.LogisticRegression()\n",
    "\n",
    "result = lm.fit(X,y)\n",
    "predictions = lm.predict(X)\n",
    "print \"Score:\",result.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import cross_validation\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3,\n",
    "                           weights=\"uniform\",\n",
    "                           p=2,\n",
    "                           metric=\"minkowski\")\n",
    "\n",
    "\n",
    "\n",
    "cv_indices = cross_validation.StratifiedKFold(y, n_folds=3)\n",
    "\n",
    "def accuracy_crossvalidator(X, y, knn, cv_indices):\n",
    "    scores = []\n",
    "    for train_i, test_i in cv_indices:\n",
    "        X_train = X[train_i, :]\n",
    "        X_test = X[test_i, :]\n",
    "\n",
    "        y_train = y[train_i]\n",
    "        y_test = y[test_i]\n",
    "\n",
    "        knn.fit(X_train, y_train)\n",
    "        \n",
    "        acc = knn.score(X_test, y_test)\n",
    "        scores.append(acc)\n",
    "        pred = knn.predict_proba(X_test)\n",
    "        \n",
    "        print('Fold accuracy:', acc)\n",
    "        print pred\n",
    "    print('Mean CV accuracy:', np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1255-f16167c22d5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy_crossvalidator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1254-bfa2b07928f4>\u001b[0m in \u001b[0;36maccuracy_crossvalidator\u001b[0;34m(X, y, knn, cv_indices)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtrain_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcv_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Lola/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1990\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1991\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1992\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1994\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Lola/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1997\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1998\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1999\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2001\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Lola/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1341\u001b[0m         \u001b[0;34m\"\"\"Return the cached item, item represents a label indexer.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m         \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_item_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1343\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "accuracy_crossvalidator(X, y, knn, cv_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def binTitle(title):\n",
    "    jobtitle  = title.lower()\n",
    "    #for i in newData[\"Job Title\"]:\n",
    "        #print \n",
    "    if (\"machine learning\" in jobtitle):\n",
    "        return 0\n",
    "    if (\"data engineer\" in jobtitle):\n",
    "        return 1\n",
    "    if (\"quantitative analyst\" in jobtitle):\n",
    "        return 2\n",
    "    if (\"software\" in jobtitle)|(\"engineer\" in jobtitle)|(\"developer\" in jobtitle):\n",
    "        return 3\n",
    "    if (\"research analyst\" in jobtitle):\n",
    "        return 4\n",
    "    if (\"data scientist\" in jobtitle):\n",
    "        return 5\n",
    "    if (\"data analyst\" in jobtitle):\n",
    "        return 6\n",
    "    if (\"scientist\" in jobtitle):\n",
    "        return 7\n",
    "    if (\"manager\" in jobtitle):\n",
    "        return 8\n",
    "    if (\"director\" in jobtitle):\n",
    "        return 9\n",
    "    if (\"architect\" in jobtitle):\n",
    "        return 10\n",
    "    else:\n",
    "        return 11\n",
    "newData[\"titleBin\"] = newData[\"Job Title\"].apply(binTitle)\n",
    "dummyData = pd.get_dummies(newData[\"titleBin\"], prefix=\"Title\")\n",
    "newData\n",
    "newData2 = newData[ [\"Salary\", \"Company Name\", \"Job Summary\", \"Job Title\", \n",
    "                     \"Atlanta\", \"Austin\", \"Chicago\", \"Los Angeles\", \"San Francisco\", \n",
    "                     \"Washington\", \"Intercept\"] ].join(dummyData)\n",
    "newData2.head()\n",
    "#otherList = []\n",
    "#for i in newData[\"titleBin\"].tolist():\n",
    "    #if i == 2:\n",
    "     #   otherList.append(i)\n",
    "#print len(otherList)/float(len(newData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Salary</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Job Summary</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Atlanta</th>\n",
       "      <th>Austin</th>\n",
       "      <th>Chicago</th>\n",
       "      <th>Los Angeles</th>\n",
       "      <th>San Francisco</th>\n",
       "      <th>Washington</th>\n",
       "      <th>...</th>\n",
       "      <th>Title_2</th>\n",
       "      <th>Title_3</th>\n",
       "      <th>Title_4</th>\n",
       "      <th>Title_5</th>\n",
       "      <th>Title_6</th>\n",
       "      <th>Title_7</th>\n",
       "      <th>Title_8</th>\n",
       "      <th>Title_9</th>\n",
       "      <th>Title_10</th>\n",
       "      <th>Title_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>S&amp;P Global Ratings</td>\n",
       "      <td>Research and resolve data maintenance requests related to Corporate &amp; Government and Structured Finance ratings data....</td>\n",
       "      <td>Statistician</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>Bloomberg's Global Data division houses an incredible team of data oriented professionals who work to solve tangible business challenges....</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>AllianceBernstein</td>\n",
       "      <td>Job Number: 7473 Position Title: VP/Research Analyst Location_formattedLocationLong: New York, New York US External Description: Research is the</td>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>Evaluate cutting-edge big data technologies/software (e.g. Strong Computer Science fundamentals (algorithms, data structures)....</td>\n",
       "      <td>Senior Data Engineer for Search and Discoverability Team</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>eTemp</td>\n",
       "      <td>High growth company focused on using data science to transform the way individuals are hired, is looking for an inventive, collaborative, methodologically...</td>\n",
       "      <td>Mid - Senior Level Data Scientist</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>MLB Advanced Media</td>\n",
       "      <td>Undergraduate (Bachelors) degree with (3) years of experience in data research, predictive modeling, statistical analysis, data transformation and / or other...</td>\n",
       "      <td>Senior Statistical Analyst</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>NBCUniversal</td>\n",
       "      <td>Strong analytical skills, able to analyze qualitative and quantitative data with client needs in mind. Analyze and interpret ratings data across the NBC Owned...</td>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>IPG Mediabrands</td>\n",
       "      <td>Present findings and back up recommendations with hard data. Brainstorm new ways of utilizing data to determine valuable business insights....</td>\n",
       "      <td>Reprise - Statistical Analyst, SEO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>Samsung Accelerator</td>\n",
       "      <td>Solid foundation in data structures, algorithms, distributed systems and software design. Who We Are Looking For:....</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>Two Sigma Investments, LLC.</td>\n",
       "      <td>Analysts, Data Scientists, Traders, and Quantitative Software Engineers. Actively collecting, interpreting, and distributing useful market data and intelligence...</td>\n",
       "      <td>Recruiter, Quant Research &amp; Trading</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>Columbia University</td>\n",
       "      <td>The lab, integrates the full spectrum of computational and experimental approaches and techniques, with specific focus on high-throughput data generation....</td>\n",
       "      <td>Associate Research Scientist</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>The Nielsen Company</td>\n",
       "      <td>Able to synthesize data &amp; simplify findings by creating reports through charts/graphs. Assist and network with industry leading clients to simplify their data...</td>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>Xaxis</td>\n",
       "      <td>Xaxis combines proprietary technology, unique data assets and exclusive media relationships with the brightest team of audience analysts, data scientists and...</td>\n",
       "      <td>Analyst, Automated Trading</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>DISH Network</td>\n",
       "      <td>A successful Data Scientist will have the following:. Developing critical analytics using key DISH data sources including the viewer measurement data and...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>Two Sigma Investments, LLC.</td>\n",
       "      <td>Developing trading strategies, from idea generation and data collection to analysis and model creation;...</td>\n",
       "      <td>Quantitative Research Associate</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>New York University College of Dentistry</td>\n",
       "      <td>JUNIOR RESEARCH SCIENTIST*. Uses computers for word processing, data acquisition and statistical analysis....</td>\n",
       "      <td>JUNIOR RESEARCH SCIENTIST McDevitt Research Laboratory</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>JPMorgan Chase</td>\n",
       "      <td>Data Scientist - New York, NY. This includes a balance of marketing/campaign optimization, data wrangling and data science....</td>\n",
       "      <td>Digital Marketing  Sr. Data Scientist - New York, NY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>Mount Sinai Health System</td>\n",
       "      <td>The data collection process. For data collection and analysis. Reliable data for entry into the Program. Website and assuring the transmission of completed data...</td>\n",
       "      <td>QUALITY IMPROVEMENT RESEARCH ANALYST</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>KUONI</td>\n",
       "      <td>Ability to aggregate data and format in a visually presentable way in MS Excel, Powerpoint, Word. Generate reports from GTA databases (Atlas, Sales Force,...</td>\n",
       "      <td>Quantitative Business Analyst</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>1199SEIU Family of Funds</td>\n",
       "      <td>Prepare data requests and reports. Manage and review payroll postings to ensure they are entered accurately and efficiently....</td>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>Mount Sinai Health System</td>\n",
       "      <td>Collects and records study data. Ensures accurate and complete compilation of subject data through chart reviews....</td>\n",
       "      <td>CLINICAL RESEARCH ASSISTANT I</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>Memorial Sloan Kettering</td>\n",
       "      <td>Interact with team members and individuals across MSK regarding data input. You are comfortable with or interested in working with and organizing large amounts...</td>\n",
       "      <td>Research Study Assistant I</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>NBCUniversal</td>\n",
       "      <td>He/she will work with cross functionally in the planning, creation and communication of trends and insights through data analysis and storytelling....</td>\n",
       "      <td>Senior Analyst, Strategic Research &amp; Insights</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>Voya Financial</td>\n",
       "      <td>Proactively uncover and resolve data and calculation issues. Maintain and expand the internal data warehouse from which the analytics are generated....</td>\n",
       "      <td>Quantitative Analyst</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>Cardiovascular Research Foundation</td>\n",
       "      <td>Develops query designs, standard tables for the presentation of data, analyses of data and reports as requested....</td>\n",
       "      <td>Clinical SAS Statistical Programmer  Contract</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>Spotify</td>\n",
       "      <td>You have experience with a range of data science techniques including clustering, machine learning, and network analysis....</td>\n",
       "      <td>Research Lead / Data Scientist</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>Machine learning, recommendation systems, pattern recognition, data mining or artificial intelligence. The position will involve taking these skills and...</td>\n",
       "      <td>Software Engineer, Machine Learning</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>Xaxis</td>\n",
       "      <td>Xaxis combines proprietary technology, unique data assets and exclusive media relationships with the brightest team of audience analysts, data scientists and...</td>\n",
       "      <td>Analyst, Strategy and Investment</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>Squarespace</td>\n",
       "      <td>Experience with a large scale data processing tools such as Apache Spark. Squarespace has access to incredibly rich data sources of both content creation and...</td>\n",
       "      <td>Software Engineer - Machine Learning</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>Enigma</td>\n",
       "      <td>We value data scientists who can quickly implement elegant solutions to complex problems. As a Senior Data Scientist with the Analytics group your contributions...</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>1</td>\n",
       "      <td>BRMi</td>\n",
       "      <td>Data governance, data architecture, data engineering, data operations, data mining, and data analysis services....</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>1</td>\n",
       "      <td>TechINT Solutions Group</td>\n",
       "      <td>TSG\\_0004 Data Scientist Mid &amp; Sr. Develop, validate, and implement data models to solve problems/answer questions....</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>1</td>\n",
       "      <td>Booz Allen Hamilton</td>\n",
       "      <td>Experience in the application of data science and advanced data analytics, including structured, unstructured, or relational and data mining and machine...</td>\n",
       "      <td>Chief Data Scientist</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>1</td>\n",
       "      <td>Booz Allen Hamilton</td>\n",
       "      <td>Experience with machine learning, data mining, clustering, algorithm development, or statistical analysis....</td>\n",
       "      <td>Data Scientist, Senior</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>1</td>\n",
       "      <td>CACI International Inc</td>\n",
       "      <td>As Data Scientist, you will be responsible for data analytics support, from understanding and evaluating customer requirements to development of advanced data...</td>\n",
       "      <td>Data Scientist Job</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>1</td>\n",
       "      <td>IBM</td>\n",
       "      <td>Data and technology are transforming industries, society and even the workplaceby creating professions that didnt exist before the emergence of data, cloud,...</td>\n",
       "      <td>Cybersecurity Data Scientist</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>1</td>\n",
       "      <td>The Advisory Board Company</td>\n",
       "      <td>Data Scientist, Engineering *LI. Experience with data warehousing, data pipeline management, and/or Hadoop development....</td>\n",
       "      <td>Data Scientist, Engineering</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>1</td>\n",
       "      <td>Department Of Education</td>\n",
       "      <td>Strong research methods and data analytic skills; (4) analyze data and synthesize information from education research and related areas;...</td>\n",
       "      <td>Senior Education Research Scientist/Analyst, AD-1730-00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>1</td>\n",
       "      <td>Selby Jennings</td>\n",
       "      <td>Senior Data Scientist. An award-winning advertising company in the DC area is looking for several Senior Data Scientists to join their team....</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>1</td>\n",
       "      <td>GEICO</td>\n",
       "      <td>Lead Data Scientist. You will coordinate project teams of Data Scientists and act as a primary point of contact in delivering innovative, high-quality data...</td>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>1</td>\n",
       "      <td>Department Of Veterans Affairs</td>\n",
       "      <td>Scientists to serve on peer review committees; Data, and presents results through presentations and/or publications....</td>\n",
       "      <td>Health Science Officer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>1</td>\n",
       "      <td>Department Of The Interior</td>\n",
       "      <td>The Fish and Wildlife Service employs world-class scientists and other professionals who are also addressing climate change, the greatest environmental and...</td>\n",
       "      <td>Senior Executive Service - Assistant Director for Science Ap...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>1</td>\n",
       "      <td>Department Of Homeland Security</td>\n",
       "      <td>Cross-reference USCIS data, create data product for use by agency data. Providing tools and support for analysis of data while overseeing OIT's data....</td>\n",
       "      <td>IT PROGRAM MANAGER</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>1</td>\n",
       "      <td>xentity corporation</td>\n",
       "      <td>Experience in data lifecycle including program planning, various data acquisition techniques including remote sensing, surveying, and partnering, familiar with...</td>\n",
       "      <td>Government Enterprise Architect</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>1</td>\n",
       "      <td>McGraw Hill Financial</td>\n",
       "      <td>The division is ahighly skilled team of data scientists, statisticians, methodologists and psychologists. They will also conduct statistical analysis to support...</td>\n",
       "      <td>Program Director, Government</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>1</td>\n",
       "      <td>Department Of Energy</td>\n",
       "      <td>Develop budgets and creates resource plans to manage ongoing operations, develop and improve data publications and produce analytic studies....</td>\n",
       "      <td>Interdisciplinary Supervisory Economist/Operations Research...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>1</td>\n",
       "      <td>Metabiota</td>\n",
       "      <td>Interface significantly with onshore and offshore engineering teams, modelers and data scientists. You will interface with customers and other product leaders...</td>\n",
       "      <td>Product Manager/Senior Product Manager</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>1</td>\n",
       "      <td>Department Of Commerce</td>\n",
       "      <td>Or in the social sciences including demography, history, economics, social welfare, geography, international relations, social or cultural anthropology, health...</td>\n",
       "      <td>Survey Statistician, GG-1530-14, Census-DE-AC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>1</td>\n",
       "      <td>xentity corporation</td>\n",
       "      <td>We are a fast-growing data consulting and support services firm. Up to date on new architecture patterns (ROA, Semantic, Big Data), software frameworks, new...</td>\n",
       "      <td>Independent Consultant - Government Solution Architect</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>1</td>\n",
       "      <td>Thermopylae Sciences + Technology</td>\n",
       "      <td>Senior Data Scientist / Software Engineer (TS/SCI). Includes statistical analyses, data visualization, data mining, and data cleansing/transformation....</td>\n",
       "      <td>Senior Data Scientist/Software Engineer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>1</td>\n",
       "      <td>Nuclear Threat Initiative</td>\n",
       "      <td>The organization works with presidents and prime ministers, scientists and technicians, educators and students, and people from around the world....</td>\n",
       "      <td>Chief Financial Officer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>1</td>\n",
       "      <td>Civis Analytics</td>\n",
       "      <td>Thorough understanding of data analytics. Civis Analytics is a technology company full of data scientists and coders, yet fully understands the importance of...</td>\n",
       "      <td>Business Development Executive, Politics and Advocacy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>1</td>\n",
       "      <td>American Chemical Society</td>\n",
       "      <td>Comprehensive understanding of applicable practices and laws relating to data privacy and protection. Ensures alignment among technology groups and business...</td>\n",
       "      <td>Chief Information Security Officer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>1</td>\n",
       "      <td>Macropace Technologies</td>\n",
       "      <td>Work with our Data Scientists and Engineers to create new datasets, experiments and technology. You will know where all the data goes, and who to call if the...</td>\n",
       "      <td>DevOps Engineer - Washington, DC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>1</td>\n",
       "      <td>The Advisory Board Company</td>\n",
       "      <td>Whether through best practice research, data analytics, technology, or consulting services, our 650+ researchers, consultants, engineers, and data scientists...</td>\n",
       "      <td>Product Manager, New Product Development</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>1</td>\n",
       "      <td>Socrata</td>\n",
       "      <td>Too often, this data is inaccessible and only useful if youre a database administrator, or a data scientist. Must have experience in and a passion for helping...</td>\n",
       "      <td>Senior Program Manager</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>1</td>\n",
       "      <td>Strategic IT Staffing</td>\n",
       "      <td>Doing all this with an exceptional group of software engineers, data scientists, dev-ops engineers and managers....</td>\n",
       "      <td>Senior DevOps Engineer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>1</td>\n",
       "      <td>ReliaSource</td>\n",
       "      <td>Includes statistical analyses, data visualization, data mining, and data cleansing / transformation. In Big data paradigms....</td>\n",
       "      <td>Senior Data Scientist / Software Engineer 4 (TS SCI CI Poly)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>1</td>\n",
       "      <td>Department Of Commerce</td>\n",
       "      <td>Provide guidance and advice for various methodological issues such as disclosure avoidance, data editing, and missing data....</td>\n",
       "      <td>Supvy Interdisciplinary Mathematical Statistician/Survey Sta...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>1</td>\n",
       "      <td>Jefferson Science Associates</td>\n",
       "      <td>The international user community includes over 1,500 scientists over half of whom are actively involved in the Labs experimental program....</td>\n",
       "      <td>Director for the Thomas Jefferson National Accelerator Facil...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1244 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Salary                              Company Name  \\\n",
       "0          0                        S&P Global Ratings   \n",
       "1          0                                 Bloomberg   \n",
       "2          0                         AllianceBernstein   \n",
       "3          0                                 Bloomberg   \n",
       "4          0                                     eTemp   \n",
       "5          0                        MLB Advanced Media   \n",
       "6          0                              NBCUniversal   \n",
       "7          0                           IPG Mediabrands   \n",
       "8          0                       Samsung Accelerator   \n",
       "9          0               Two Sigma Investments, LLC.   \n",
       "10         0                       Columbia University   \n",
       "11         0                       The Nielsen Company   \n",
       "12         0                                     Xaxis   \n",
       "13         0                              DISH Network   \n",
       "14         0               Two Sigma Investments, LLC.   \n",
       "15         0  New York University College of Dentistry   \n",
       "16         0                            JPMorgan Chase   \n",
       "17         0                 Mount Sinai Health System   \n",
       "18         0                                     KUONI   \n",
       "19         0                  1199SEIU Family of Funds   \n",
       "20         0                 Mount Sinai Health System   \n",
       "21         0                  Memorial Sloan Kettering   \n",
       "22         0                              NBCUniversal   \n",
       "23         0                            Voya Financial   \n",
       "24         0        Cardiovascular Research Foundation   \n",
       "25         0                                   Spotify   \n",
       "26         0                                  Facebook   \n",
       "27         0                                     Xaxis   \n",
       "28         0                               Squarespace   \n",
       "29         0                                    Enigma   \n",
       "...      ...                                       ...   \n",
       "1214       1                                      BRMi   \n",
       "1215       1                   TechINT Solutions Group   \n",
       "1216       1                       Booz Allen Hamilton   \n",
       "1217       1                       Booz Allen Hamilton   \n",
       "1218       1                    CACI International Inc   \n",
       "1219       1                                       IBM   \n",
       "1220       1                The Advisory Board Company   \n",
       "1221       1                   Department Of Education   \n",
       "1222       1                            Selby Jennings   \n",
       "1223       1                                     GEICO   \n",
       "1224       1            Department Of Veterans Affairs   \n",
       "1225       1                Department Of The Interior   \n",
       "1226       1           Department Of Homeland Security   \n",
       "1227       1                       xentity corporation   \n",
       "1228       1                     McGraw Hill Financial   \n",
       "1229       1                      Department Of Energy   \n",
       "1230       1                                 Metabiota   \n",
       "1231       1                    Department Of Commerce   \n",
       "1232       1                       xentity corporation   \n",
       "1233       1         Thermopylae Sciences + Technology   \n",
       "1234       1                 Nuclear Threat Initiative   \n",
       "1235       1                           Civis Analytics   \n",
       "1236       1                 American Chemical Society   \n",
       "1237       1                    Macropace Technologies   \n",
       "1238       1                The Advisory Board Company   \n",
       "1239       1                                   Socrata   \n",
       "1240       1                     Strategic IT Staffing   \n",
       "1241       1                               ReliaSource   \n",
       "1242       1                    Department Of Commerce   \n",
       "1243       1              Jefferson Science Associates   \n",
       "\n",
       "                                                                                                                                                              Job Summary  \\\n",
       "0                                                Research and resolve data maintenance requests related to Corporate & Government and Structured Finance ratings data....   \n",
       "1                            Bloomberg's Global Data division houses an incredible team of data oriented professionals who work to solve tangible business challenges....   \n",
       "2                        Job Number: 7473 Position Title: VP/Research Analyst Location_formattedLocationLong: New York, New York US External Description: Research is the   \n",
       "3                                       Evaluate cutting-edge big data technologies/software (e.g. Strong Computer Science fundamentals (algorithms, data structures)....   \n",
       "4           High growth company focused on using data science to transform the way individuals are hired, is looking for an inventive, collaborative, methodologically...   \n",
       "5        Undergraduate (Bachelors) degree with (3) years of experience in data research, predictive modeling, statistical analysis, data transformation and / or other...   \n",
       "6       Strong analytical skills, able to analyze qualitative and quantitative data with client needs in mind. Analyze and interpret ratings data across the NBC Owned...   \n",
       "7                          Present findings and back up recommendations with hard data. Brainstorm new ways of utilizing data to determine valuable business insights....   \n",
       "8                                                   Solid foundation in data structures, algorithms, distributed systems and software design. Who We Are Looking For:....   \n",
       "9     Analysts, Data Scientists, Traders, and Quantitative Software Engineers. Actively collecting, interpreting, and distributing useful market data and intelligence...   \n",
       "10          The lab, integrates the full spectrum of computational and experimental approaches and techniques, with specific focus on high-throughput data generation....   \n",
       "11      Able to synthesize data & simplify findings by creating reports through charts/graphs. Assist and network with industry leading clients to simplify their data...   \n",
       "12       Xaxis combines proprietary technology, unique data assets and exclusive media relationships with the brightest team of audience analysts, data scientists and...   \n",
       "13           A successful Data Scientist will have the following:. Developing critical analytics using key DISH data sources including the viewer measurement data and...   \n",
       "14                                                             Developing trading strategies, from idea generation and data collection to analysis and model creation;...   \n",
       "15                                                          JUNIOR RESEARCH SCIENTIST*. Uses computers for word processing, data acquisition and statistical analysis....   \n",
       "16                                         Data Scientist - New York, NY. This includes a balance of marketing/campaign optimization, data wrangling and data science....   \n",
       "17    The data collection process. For data collection and analysis. Reliable data for entry into the Program. Website and assuring the transmission of completed data...   \n",
       "18          Ability to aggregate data and format in a visually presentable way in MS Excel, Powerpoint, Word. Generate reports from GTA databases (Atlas, Sales Force,...   \n",
       "19                                        Prepare data requests and reports. Manage and review payroll postings to ensure they are entered accurately and efficiently....   \n",
       "20                                                   Collects and records study data. Ensures accurate and complete compilation of subject data through chart reviews....   \n",
       "21     Interact with team members and individuals across MSK regarding data input. You are comfortable with or interested in working with and organizing large amounts...   \n",
       "22                 He/she will work with cross functionally in the planning, creation and communication of trends and insights through data analysis and storytelling....   \n",
       "23                Proactively uncover and resolve data and calculation issues. Maintain and expand the internal data warehouse from which the analytics are generated....   \n",
       "24                                                    Develops query designs, standard tables for the presentation of data, analyses of data and reports as requested....   \n",
       "25                                           You have experience with a range of data science techniques including clustering, machine learning, and network analysis....   \n",
       "26            Machine learning, recommendation systems, pattern recognition, data mining or artificial intelligence. The position will involve taking these skills and...   \n",
       "27       Xaxis combines proprietary technology, unique data assets and exclusive media relationships with the brightest team of audience analysts, data scientists and...   \n",
       "28       Experience with a large scale data processing tools such as Apache Spark. Squarespace has access to incredibly rich data sources of both content creation and...   \n",
       "29    We value data scientists who can quickly implement elegant solutions to complex problems. As a Senior Data Scientist with the Analytics group your contributions...   \n",
       "...                                                                                                                                                                   ...   \n",
       "1214                                                   Data governance, data architecture, data engineering, data operations, data mining, and data analysis services....   \n",
       "1215                                               TSG\\_0004 Data Scientist Mid & Sr. Develop, validate, and implement data models to solve problems/answer questions....   \n",
       "1216          Experience in the application of data science and advanced data analytics, including structured, unstructured, or relational and data mining and machine...   \n",
       "1217                                                        Experience with machine learning, data mining, clustering, algorithm development, or statistical analysis....   \n",
       "1218    As Data Scientist, you will be responsible for data analytics support, from understanding and evaluating customer requirements to development of advanced data...   \n",
       "1219    Data and technology are transforming industries, society and even the workplaceby creating professions that didnt exist before the emergence of data, cloud,...   \n",
       "1220                                           Data Scientist, Engineering *LI. Experience with data warehousing, data pipeline management, and/or Hadoop development....   \n",
       "1221                          Strong research methods and data analytic skills; (4) analyze data and synthesize information from education research and related areas;...   \n",
       "1222                      Senior Data Scientist. An award-winning advertising company in the DC area is looking for several Senior Data Scientists to join their team....   \n",
       "1223       Lead Data Scientist. You will coordinate project teams of Data Scientists and act as a primary point of contact in delivering innovative, high-quality data...   \n",
       "1224                                              Scientists to serve on peer review committees; Data, and presents results through presentations and/or publications....   \n",
       "1225       The Fish and Wildlife Service employs world-class scientists and other professionals who are also addressing climate change, the greatest environmental and...   \n",
       "1226             Cross-reference USCIS data, create data product for use by agency data. Providing tools and support for analysis of data while overseeing OIT's data....   \n",
       "1227   Experience in data lifecycle including program planning, various data acquisition techniques including remote sensing, surveying, and partnering, familiar with...   \n",
       "1228  The division is ahighly skilled team of data scientists, statisticians, methodologists and psychologists. They will also conduct statistical analysis to support...   \n",
       "1229                      Develop budgets and creates resource plans to manage ongoing operations, develop and improve data publications and produce analytic studies....   \n",
       "1230    Interface significantly with onshore and offshore engineering teams, modelers and data scientists. You will interface with customers and other product leaders...   \n",
       "1231   Or in the social sciences including demography, history, economics, social welfare, geography, international relations, social or cultural anthropology, health...   \n",
       "1232      We are a fast-growing data consulting and support services firm. Up to date on new architecture patterns (ROA, Semantic, Big Data), software frameworks, new...   \n",
       "1233            Senior Data Scientist / Software Engineer (TS/SCI). Includes statistical analyses, data visualization, data mining, and data cleansing/transformation....   \n",
       "1234                 The organization works with presidents and prime ministers, scientists and technicians, educators and students, and people from around the world....   \n",
       "1235     Thorough understanding of data analytics. Civis Analytics is a technology company full of data scientists and coders, yet fully understands the importance of...   \n",
       "1236      Comprehensive understanding of applicable practices and laws relating to data privacy and protection. Ensures alignment among technology groups and business...   \n",
       "1237     Work with our Data Scientists and Engineers to create new datasets, experiments and technology. You will know where all the data goes, and who to call if the...   \n",
       "1238     Whether through best practice research, data analytics, technology, or consulting services, our 650+ researchers, consultants, engineers, and data scientists...   \n",
       "1239   Too often, this data is inaccessible and only useful if youre a database administrator, or a data scientist. Must have experience in and a passion for helping...   \n",
       "1240                                                  Doing all this with an exceptional group of software engineers, data scientists, dev-ops engineers and managers....   \n",
       "1241                                       Includes statistical analyses, data visualization, data mining, and data cleansing / transformation. In Big data paradigms....   \n",
       "1242                                       Provide guidance and advice for various methodological issues such as disclosure avoidance, data editing, and missing data....   \n",
       "1243                        The international user community includes over 1,500 scientists over half of whom are actively involved in the Labs experimental program....   \n",
       "\n",
       "                                                            Job Title  \\\n",
       "0                                                        Statistician   \n",
       "1                                           Machine Learning Engineer   \n",
       "2                                                    Research Analyst   \n",
       "3            Senior Data Engineer for Search and Discoverability Team   \n",
       "4                                   Mid - Senior Level Data Scientist   \n",
       "5                                          Senior Statistical Analyst   \n",
       "6                                                    Research Analyst   \n",
       "7                                  Reprise - Statistical Analyst, SEO   \n",
       "8                                           Machine Learning Engineer   \n",
       "9                                 Recruiter, Quant Research & Trading   \n",
       "10                                       Associate Research Scientist   \n",
       "11                                                   Research Analyst   \n",
       "12                                         Analyst, Automated Trading   \n",
       "13                                                     Data Scientist   \n",
       "14                                    Quantitative Research Associate   \n",
       "15             JUNIOR RESEARCH SCIENTIST McDevitt Research Laboratory   \n",
       "16              Digital Marketing  Sr. Data Scientist - New York, NY   \n",
       "17                               QUALITY IMPROVEMENT RESEARCH ANALYST   \n",
       "18                                      Quantitative Business Analyst   \n",
       "19                                                   Research Analyst   \n",
       "20                                      CLINICAL RESEARCH ASSISTANT I   \n",
       "21                                         Research Study Assistant I   \n",
       "22                      Senior Analyst, Strategic Research & Insights   \n",
       "23                                               Quantitative Analyst   \n",
       "24                     Clinical SAS Statistical Programmer  Contract   \n",
       "25                                     Research Lead / Data Scientist   \n",
       "26                                Software Engineer, Machine Learning   \n",
       "27                                   Analyst, Strategy and Investment   \n",
       "28                               Software Engineer - Machine Learning   \n",
       "29                                              Senior Data Scientist   \n",
       "...                                                               ...   \n",
       "1214                                                   Data Scientist   \n",
       "1215                                                   Data Scientist   \n",
       "1216                                             Chief Data Scientist   \n",
       "1217                                           Data Scientist, Senior   \n",
       "1218                                               Data Scientist Job   \n",
       "1219                                     Cybersecurity Data Scientist   \n",
       "1220                                      Data Scientist, Engineering   \n",
       "1221          Senior Education Research Scientist/Analyst, AD-1730-00   \n",
       "1222                                            Senior Data Scientist   \n",
       "1223                                              Lead Data Scientist   \n",
       "1224                                           Health Science Officer   \n",
       "1225  Senior Executive Service - Assistant Director for Science Ap...   \n",
       "1226                                               IT PROGRAM MANAGER   \n",
       "1227                                  Government Enterprise Architect   \n",
       "1228                                     Program Director, Government   \n",
       "1229   Interdisciplinary Supervisory Economist/Operations Research...   \n",
       "1230                           Product Manager/Senior Product Manager   \n",
       "1231                    Survey Statistician, GG-1530-14, Census-DE-AC   \n",
       "1232           Independent Consultant - Government Solution Architect   \n",
       "1233                          Senior Data Scientist/Software Engineer   \n",
       "1234                                          Chief Financial Officer   \n",
       "1235            Business Development Executive, Politics and Advocacy   \n",
       "1236                               Chief Information Security Officer   \n",
       "1237                                 DevOps Engineer - Washington, DC   \n",
       "1238                         Product Manager, New Product Development   \n",
       "1239                                           Senior Program Manager   \n",
       "1240                                           Senior DevOps Engineer   \n",
       "1241     Senior Data Scientist / Software Engineer 4 (TS SCI CI Poly)   \n",
       "1242  Supvy Interdisciplinary Mathematical Statistician/Survey Sta...   \n",
       "1243  Director for the Thomas Jefferson National Accelerator Facil...   \n",
       "\n",
       "      Atlanta  Austin  Chicago  Los Angeles  San Francisco  Washington  \\\n",
       "0         0.0     0.0      0.0          0.0            0.0         0.0   \n",
       "1         0.0     0.0      0.0          0.0            0.0         0.0   \n",
       "2         0.0     0.0      0.0          0.0            0.0         0.0   \n",
       "3         0.0     0.0      0.0          0.0            0.0         0.0   \n",
       "4         0.0     0.0      0.0          0.0            0.0         0.0   \n",
       "5         0.0     0.0      0.0          0.0            0.0         0.0   \n",
       "6         0.0     0.0      0.0          0.0            0.0         0.0   \n",
       "7         0.0     0.0      0.0          0.0            0.0         0.0   \n",
       "8         0.0     0.0      0.0          0.0            0.0         0.0   \n",
       "9         0.0     0.0      0.0          0.0            0.0         0.0   \n",
       "10        0.0     0.0      0.0          0.0            0.0         0.0   \n",
       "11        0.0     0.0      0.0          0.0            0.0         0.0   \n",
       "12        0.0     0.0      0.0          0.0            0.0         0.0   \n",
       "13        0.0     0.0      0.0          0.0            0.0         0.0   \n",
       "14        0.0     0.0      0.0          0.0            0.0         0.0   \n",
       "15        0.0     0.0      0.0          0.0            0.0         0.0   \n",
       "16        0.0     0.0      0.0          0.0            0.0         0.0   \n",
       "17        0.0     0.0      0.0          0.0            0.0         0.0   \n",
       "18        0.0     0.0      0.0          0.0            0.0         0.0   \n",
       "19        0.0     0.0      0.0          0.0            0.0         0.0   \n",
       "20        0.0     0.0      0.0          0.0            0.0         0.0   \n",
       "21        0.0     0.0      0.0          0.0            0.0         0.0   \n",
       "22        0.0     0.0      0.0          0.0            0.0         0.0   \n",
       "23        0.0     0.0      0.0          0.0            0.0         0.0   \n",
       "24        0.0     0.0      0.0          0.0            0.0         0.0   \n",
       "25        0.0     0.0      0.0          0.0            0.0         0.0   \n",
       "26        0.0     0.0      0.0          0.0            0.0         0.0   \n",
       "27        0.0     0.0      0.0          0.0            0.0         0.0   \n",
       "28        0.0     0.0      0.0          0.0            0.0         0.0   \n",
       "29        0.0     0.0      0.0          0.0            0.0         0.0   \n",
       "...       ...     ...      ...          ...            ...         ...   \n",
       "1214      0.0     0.0      0.0          0.0            0.0         1.0   \n",
       "1215      0.0     0.0      0.0          0.0            0.0         1.0   \n",
       "1216      0.0     0.0      0.0          0.0            0.0         1.0   \n",
       "1217      0.0     0.0      0.0          0.0            0.0         1.0   \n",
       "1218      0.0     0.0      0.0          0.0            0.0         1.0   \n",
       "1219      0.0     0.0      0.0          0.0            0.0         1.0   \n",
       "1220      0.0     0.0      0.0          0.0            0.0         1.0   \n",
       "1221      0.0     0.0      0.0          0.0            0.0         1.0   \n",
       "1222      0.0     0.0      0.0          0.0            0.0         1.0   \n",
       "1223      0.0     0.0      0.0          0.0            0.0         1.0   \n",
       "1224      0.0     0.0      0.0          0.0            0.0         1.0   \n",
       "1225      0.0     0.0      0.0          0.0            0.0         1.0   \n",
       "1226      0.0     0.0      0.0          0.0            0.0         1.0   \n",
       "1227      0.0     0.0      0.0          0.0            0.0         1.0   \n",
       "1228      0.0     0.0      0.0          0.0            0.0         1.0   \n",
       "1229      0.0     0.0      0.0          0.0            0.0         1.0   \n",
       "1230      0.0     0.0      0.0          0.0            0.0         1.0   \n",
       "1231      0.0     0.0      0.0          0.0            0.0         1.0   \n",
       "1232      0.0     0.0      0.0          0.0            0.0         1.0   \n",
       "1233      0.0     0.0      0.0          0.0            0.0         1.0   \n",
       "1234      0.0     0.0      0.0          0.0            0.0         1.0   \n",
       "1235      0.0     0.0      0.0          0.0            0.0         1.0   \n",
       "1236      0.0     0.0      0.0          0.0            0.0         1.0   \n",
       "1237      0.0     0.0      0.0          0.0            0.0         1.0   \n",
       "1238      0.0     0.0      0.0          0.0            0.0         1.0   \n",
       "1239      0.0     0.0      0.0          0.0            0.0         1.0   \n",
       "1240      0.0     0.0      0.0          0.0            0.0         1.0   \n",
       "1241      0.0     0.0      0.0          0.0            0.0         1.0   \n",
       "1242      0.0     0.0      0.0          0.0            0.0         1.0   \n",
       "1243      0.0     0.0      0.0          0.0            0.0         1.0   \n",
       "\n",
       "        ...     Title_2  Title_3  Title_4  Title_5  Title_6  Title_7  Title_8  \\\n",
       "0       ...         0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1       ...         0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2       ...         0.0      0.0      1.0      0.0      0.0      0.0      0.0   \n",
       "3       ...         0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4       ...         0.0      0.0      0.0      1.0      0.0      0.0      0.0   \n",
       "5       ...         0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "6       ...         0.0      0.0      1.0      0.0      0.0      0.0      0.0   \n",
       "7       ...         0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "8       ...         0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "9       ...         0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "10      ...         0.0      0.0      0.0      0.0      0.0      1.0      0.0   \n",
       "11      ...         0.0      0.0      1.0      0.0      0.0      0.0      0.0   \n",
       "12      ...         0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "13      ...         0.0      0.0      0.0      1.0      0.0      0.0      0.0   \n",
       "14      ...         0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "15      ...         0.0      0.0      0.0      0.0      0.0      1.0      0.0   \n",
       "16      ...         0.0      0.0      0.0      1.0      0.0      0.0      0.0   \n",
       "17      ...         0.0      0.0      1.0      0.0      0.0      0.0      0.0   \n",
       "18      ...         0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "19      ...         0.0      0.0      1.0      0.0      0.0      0.0      0.0   \n",
       "20      ...         0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "21      ...         0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "22      ...         0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "23      ...         1.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "24      ...         0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "25      ...         0.0      0.0      0.0      1.0      0.0      0.0      0.0   \n",
       "26      ...         0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "27      ...         0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "28      ...         0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "29      ...         0.0      0.0      0.0      1.0      0.0      0.0      0.0   \n",
       "...     ...         ...      ...      ...      ...      ...      ...      ...   \n",
       "1214    ...         0.0      0.0      0.0      1.0      0.0      0.0      0.0   \n",
       "1215    ...         0.0      0.0      0.0      1.0      0.0      0.0      0.0   \n",
       "1216    ...         0.0      0.0      0.0      1.0      0.0      0.0      0.0   \n",
       "1217    ...         0.0      0.0      0.0      1.0      0.0      0.0      0.0   \n",
       "1218    ...         0.0      0.0      0.0      1.0      0.0      0.0      0.0   \n",
       "1219    ...         0.0      0.0      0.0      1.0      0.0      0.0      0.0   \n",
       "1220    ...         0.0      1.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1221    ...         0.0      0.0      0.0      0.0      0.0      1.0      0.0   \n",
       "1222    ...         0.0      0.0      0.0      1.0      0.0      0.0      0.0   \n",
       "1223    ...         0.0      0.0      0.0      1.0      0.0      0.0      0.0   \n",
       "1224    ...         0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1225    ...         0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1226    ...         0.0      0.0      0.0      0.0      0.0      0.0      1.0   \n",
       "1227    ...         0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1228    ...         0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1229    ...         0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1230    ...         0.0      0.0      0.0      0.0      0.0      0.0      1.0   \n",
       "1231    ...         0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1232    ...         0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1233    ...         0.0      1.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1234    ...         0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1235    ...         0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1236    ...         0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1237    ...         0.0      1.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1238    ...         0.0      0.0      0.0      0.0      0.0      0.0      1.0   \n",
       "1239    ...         0.0      0.0      0.0      0.0      0.0      0.0      1.0   \n",
       "1240    ...         0.0      1.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1241    ...         0.0      1.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1242    ...         0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1243    ...         0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "      Title_9  Title_10  Title_11  \n",
       "0         0.0       0.0       1.0  \n",
       "1         0.0       0.0       0.0  \n",
       "2         0.0       0.0       0.0  \n",
       "3         0.0       0.0       0.0  \n",
       "4         0.0       0.0       0.0  \n",
       "5         0.0       0.0       1.0  \n",
       "6         0.0       0.0       0.0  \n",
       "7         0.0       0.0       1.0  \n",
       "8         0.0       0.0       0.0  \n",
       "9         0.0       0.0       1.0  \n",
       "10        0.0       0.0       0.0  \n",
       "11        0.0       0.0       0.0  \n",
       "12        0.0       0.0       1.0  \n",
       "13        0.0       0.0       0.0  \n",
       "14        0.0       0.0       1.0  \n",
       "15        0.0       0.0       0.0  \n",
       "16        0.0       0.0       0.0  \n",
       "17        0.0       0.0       0.0  \n",
       "18        0.0       0.0       1.0  \n",
       "19        0.0       0.0       0.0  \n",
       "20        0.0       0.0       1.0  \n",
       "21        0.0       0.0       1.0  \n",
       "22        0.0       0.0       1.0  \n",
       "23        0.0       0.0       0.0  \n",
       "24        0.0       0.0       1.0  \n",
       "25        0.0       0.0       0.0  \n",
       "26        0.0       0.0       0.0  \n",
       "27        0.0       0.0       1.0  \n",
       "28        0.0       0.0       0.0  \n",
       "29        0.0       0.0       0.0  \n",
       "...       ...       ...       ...  \n",
       "1214      0.0       0.0       0.0  \n",
       "1215      0.0       0.0       0.0  \n",
       "1216      0.0       0.0       0.0  \n",
       "1217      0.0       0.0       0.0  \n",
       "1218      0.0       0.0       0.0  \n",
       "1219      0.0       0.0       0.0  \n",
       "1220      0.0       0.0       0.0  \n",
       "1221      0.0       0.0       0.0  \n",
       "1222      0.0       0.0       0.0  \n",
       "1223      0.0       0.0       0.0  \n",
       "1224      0.0       0.0       1.0  \n",
       "1225      1.0       0.0       0.0  \n",
       "1226      0.0       0.0       0.0  \n",
       "1227      0.0       1.0       0.0  \n",
       "1228      1.0       0.0       0.0  \n",
       "1229      0.0       0.0       1.0  \n",
       "1230      0.0       0.0       0.0  \n",
       "1231      0.0       0.0       1.0  \n",
       "1232      0.0       1.0       0.0  \n",
       "1233      0.0       0.0       0.0  \n",
       "1234      0.0       0.0       1.0  \n",
       "1235      0.0       0.0       1.0  \n",
       "1236      0.0       0.0       1.0  \n",
       "1237      0.0       0.0       0.0  \n",
       "1238      0.0       0.0       0.0  \n",
       "1239      0.0       0.0       0.0  \n",
       "1240      0.0       0.0       0.0  \n",
       "1241      0.0       0.0       0.0  \n",
       "1242      0.0       0.0       1.0  \n",
       "1243      1.0       0.0       0.0  \n",
       "\n",
       "[1244 rows x 23 columns]"
      ]
     },
     "execution_count": 1271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newData2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
